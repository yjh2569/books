# 세상을 바꾸는 기계 지능

## 머신러닝

* 머신러닝(machine learning) : 잘 조직된 훈련 데이터를 바탕으로 프로그램을 훈련시키는 것

### 베이즈

* 나이브 베이즈 분류(naive Bayes classifier) : 통계 데이터를 기반으로 새 데이터가 주어졌을 때 확률을 계산해 이를 기반으로 분류한다.
> 스팸 메시지와 일반 메시지에 대해 각 단어가 들어있는 메시지의 비율을 계산하고 이를 바탕으로 새 메시지가 주어졌을 때 그 메시지가 스팸 메시지일 확률과 일반 메시지일 확률을 계산해서 메시지가 스팸인지를 판단한다.
* 각 사건이 서로 독립적인 사건이라 가정하기에 단어 사이의 관계를 살펴보는 알고리즘을 추가하면 더 나은 분류가 가능하다.

### 가우스

* 물체의 특성을 잘 알아보기 위해서는 외형, 특히 테두리를 파악하는 것이 중요하다. 그러나 테두리는 애매모호하게 생겼기 때문에 테두리를 좀더 쉽게 찾기 위해 사진을 약간 흐릿하게 만든다.
* 가우시안 블러 : 가우스 분포를 이용해 이미지를 흐리게 만드는 방식
  * 3차원 가우스 분포를 이미지로 끌어가서 평균(중앙) 지점을 각 픽셀의 중심에 일치시킨다.
  * 곡면 아래 있는 픽셀의 값과 곡면의 값이 전체에서 차지하는 가중치을 곱한 결과를 모두 더해서 중심 픽셀의 값으로 만든다.
  * 위 과정을 컨볼루션(convolution)이라 하며, 가중치 배열을 컨볼루션 커널(kernel)이라고 한다.
* 이미지의 가장자리는 컨볼루션을 계산할 수 없는데, 이는 가장자리 근처로 너무 가까이 가지 않거나(이 경우 가로 세로가 커널 크기만큼 줄어든다) 주변에 윤곽선을 그려 이미지를 더 크게 만드는 방법 등을 통해 해결한다.

### 소벨

* 실제 테두리를 찾기 위해 밝기 변화를 이용한다.
* 밝기 변화 : 어떤 픽셀과 그 픽셀의 이웃 픽셀 사이의 밝기 차이
* 가우시안 분포의 1차 도함수의 3차원 버전과 곡면 아래 있는 픽셀의 값과 곱해서 모두 더한 값을 계산한다. 단, 변화의 크기인 규모를 계산하기 위해 마지막에 절댓값을 취한다.
* 수평 방향과 수직 방향별로 다른 버전을 사용함으로써 규모와 방향을 얻을 수도 있다.
* 여기서 얻은 방향은 테두리의 방위로 물체와의 방향이 수직이다.

### 캐니

* 비최댓값 억제(nonmaximum suppression) : 테두리를 가늘게 하기 위해 각 픽셀의 증감률 규모를 증감률 방향에 있는 이웃 셀과 비교해 가운데 픽셀의 규모가 주변 픽셀의 규모보다 하나라도 작으면 0으로 감소시킨다.
* 이력(hysteresis)을 활용한 테두리 추적 : 증감률 규모가 상단 문턱값(threshold)보다 큰 픽셀만 찾는다.
* 이 과정을 통해 물체를 나타내는 명확한 테두리를 찾을 수 있다.

### 특성 추출

* 테두리를 추적해 각 대상으로부터 특성이 되는 물체를 추출한다.
* 특성들을 이용해 주어진 대상을 분류한다.
* 지금까지 특성을 분류하는 단계를 나타내면 흐리게 하기 → 테두리 감지 → 비최댓값 억제 → 이력을 활용한 테두리 추적 → 특성 추출 → 분류 로 나눌 수 있다.

### 인공 신경망

* 실제로는 샘플이 아닌 수많은 변형들을 처리할 수 있는 수준을 원하기 때문에 더 나은 분류기가 필요하다.
* 이를 위해 인간의 뉴런을 본따 컴퓨터에서 논리 게이트와 아날로그 비교기를 활용해 구현했다.
* 각 입력의 값을 어떤 가중치로 곱한 다음, 모든 가중치가 곱해진 값을 더한다. 이후 이 값을 활동 전위와 비교해 활동 전위보다 높으면 참을, 낮으면 거짓을 반환한다.
* 초기에 퍼셉트론(perceptron)을 통해 뉴런을 구현했고, 다중 계층 신경망(multilayer neural network)으로 좀더 복잡한 문제를 해결했다.
* 앞먹임 신경망(feedforward network) : 각 계층에서 만들어진 출력을 다음 계층으로만 보내는 신경망
* 다중 계층 신경망에는 은닉 계층(hidden layer)가 입력 계층과 출력 계층 사이에 원하는 만큼 들어있다.
* 퍼셉트론의 2진법적인 특성으로 인해 가중치 결정이 어려웠기에 퍼셉트론의 비교기를 시그모이드 함수(sigmoid function)으로 바꾼 시그모이드 뉴런이 탄생했다.
* 시그모이드 뉴런에서는 역전파(backpropagation) 기법을 사용해 신경망의 가중치를 결정할 수 있다.
  * 이미 알고 있는 대상에 대한 입력을 제공한 뒤 나온 출력 결과를 예상 출력값에서 뺀 값인 오류 함수(error function)를 계산하고 이를 가능한 한 0이 되도록 가중치를 조절한다.
  * 가중치 조절은 경사 하강(gradient descent)를 이용한다.
* 순환 신경망(RNN, recurrent NN) : 순차 논리적인 변종으로 DAG가 아니라 어떤 계층의 출력이 다시 아래 계층의 입력으로 들어갈 수 있다. 출력을 저장하고 전체에 클록을 공급해서 신경망이 폭발하는 것을 방지한다. 손글씨나 음성 인식 등 순차적인 입력을 처리할 때 사용한다.
* 컨볼루션 신경망(CNN, convolution NN) : 컨볼루션 커널과 비슷한 픽셀값의 배열을 입력으로 받는다. 이미지 처리에 주로 사용한다.

## 인공지능

* 초기에는 리습(LISP) 프로그래밍 언어에서 시작되었다. 리습은 리스트 처리기라는 뜻이다.
* 프로그램을 명령어의 리스트로 간주했기 때문에 프로그램이 자기 자신을 바꿀 수 있었고, 따라서 리습 프로그램이 새로운 알고리즘을 만들거나 기존 알고리즘을 수정할 수 있었다.
* 전문가 시스템(expert system) : 질문을 던지면서 지식 데이터베이스 내부를 검색하도록 돕는다.

## 빅데이터

* 너무 크고 복잡해서 오늘날의 기술로 마구잡이식으로 처리하면 처리가 불가능한 데이터
* 분석뿐만 아니라 수집, 저장, 관리에도 적용된다.
* 수많은 정보가 연구 목적으로 익명화한 형태로 제공되지만, 빅데이터 기법을 사용하면 종종 익명화한 데이터에서 개인을 식별할 수 있다.