# 검색어 자동완성 시스템 설계

## 문제 이해 및 설계 범위 확정

### 요구사항

* 빠른 응답 속도 : 사용자가 검색어를 입력함에 따라 자동완성 검색어도 충분히 빨리 표시되어야 한다.
* 연관성 : 자동완성되는 검색어는 사용자가 입력한 단어와 연관되어야 한다.
* 정렬 : 시스템 계산 결과는 인기도 등의 순위 모델로 정렬해야 한다.
* 규모 확장성 : 많은 트래픽을 감당할 수 있게 확장 가능해야 한다.
* 고가용성 : 시스템 일부에 장애 발생, 속도 저하, 네트워크 문제 발생 시에도 계속 사용 가능해야 한다.

### 개략적 규모 추정

* 일간 능동 사용자(DAU) : 천만 명
* 평균 사용자 당 검색 수 : 10건
* 질의 시 입력 데이터 크기 : 20바이트
  * 질의문은 4개 단어, 각 단어는 평균적으로 5글자로 구성되고, ASCII를 사용한다고 가정(1글자당 1바이트)하면 4*5 = 20바이트
* 검색창에 글자 입력할 때마다 검색어 자동완성 백엔드로 요청 전달 -> 평균 1회 검색 당 요청 수 : 20건
* QPS : 24000건(천만 명 * 10질의/일 * 20자 / 24시간 / 3600초)
* 최대 QPS : QPS*2 = 48000건
* 질의 중 신규 검색어 비율 : 20% -> 매일 0.4GB(천만 명 * 10질의/일 * 20바이트 * 20%)의 신규 데이터가 시스템에 추가

## 개략적 설계안 제시 및 동의 구하기

### 데이터 수집 서비스

* 사용자가 입력한 질의를 실시간으로 수집하는 시스템
* 빈도 테이블(frequency table)이 있다고 가정
  * 검색 시 해당 테이블에 질의 추가 또는 질의에 해당하는 빈도 증가

### 질의 서비스

* 빈도 테이블이 있을 때 사용자가 어떤 문자열을 검색창에 입력했을 때 top N 자동완성 검색어가 표시되어야 한다.
* SQL 질의문을 사용해 간단히 계산할 수 있으나 데이터가 아주 많아지면 데이터베이스가 병목이 될 수 있다.

## 상세 설계

### 트라이 자료구조

* 관계형 데이터베이스를 통해 top N 검색어를 찾는 것은 효율적이지 않다.
  * 이를 보완하기 위해 트라이 자료구조를 사용한다.
* 트라이(trie)
  * 문자열들을 간략하게 저장할 수 있는 자료구조
  * 트리 형태의 자료구조
  * 루트 노드는 빈 문자열을 나타낸다.
  * 각 노드는 글자(character) 하나를 저장하고, 26개(해당 글자 다음에 등장할 수 있는 모든 글자의 개수)의 자식 노드를 가질 수 있다.
  * 각 트리 노드는 하나의 단어, 또는 접두어 문자열을 나타낸다.
* 빈도 테이블이 있는 경우 빈도수를 트라이 노드에 추가한다.
* 가장 많이 사용된 질의어 n개를 찾는 방법
  * p: 접두어 길이, n: 트라이 안 노드 개수, c: 주어진 노드의 자식 노드 개수
  * 해당 접두어를 표현하는 노드 찾기(O(p))
  * 해당 노드부터 시작하는 하위 트리를 탐색해 모든 유효 노드 찾기(O(c))
    * 유효 노드 : 유효한 검색 문자열을 구성하는 노드
  * 유효 노드들을 정렬해 top n개 찾기(O(clogc))
  * 총 시간 복잡도 : O(p)+O(c)+O(clogc)
* 최적화 방안
  * 접두어 최대 길이 제한
    * 사용자가 검색창에 긴 검색어를 입력하는 일이 거의 없기 때문이다.
    * 최대 길이를 제한하면 접두어 노드를 찾는 단계의 시간 복잡도가 O(p)에서 O(1)으로 줄어든다.
  * 노드에 인기 검색어 캐시
    * 각 노드에 n개의 인기 검색어를 저장하면 전체 트라이를 검색할 필요가 없다.
    * 시간 복잡도를 엄청나게 낮출 수 있지만(O(1)) 그만큼 질의어를 저장할 공간이 많이 필요하다.

### 데이터 수집 서비스

* 검색창에 입력할 때마다 실시간으로 데이터를 수정하면 실용적이지 못하다.
  * 매일 수천만 건의 질의마다 트라이를 갱신하면 질의 서비스가 심각하게 느려진다.
  * 트라이가 생성되면 인기 검색어는 크게 달라지지 않는다.
* 규모 확장이 쉬운 데이터 수집 서비스를 만들려면 데이터가 어디서 오고 어떻게 이용되는지를 알아야 한다.
* 용례가 달라지더라도 데이터 수집 서비스의 토대는 바뀌지 않는다.
  * 트라이를 만드는 데 쓰는 데이터는 보통 데이터 분석 서비스나 로깅 서비스로부터 올 것이기 때문이다.
* 데이터 분석 서비스 로그
  * 검색창에 입력된 질의에 관한 원본 데이터 보관
  * 새로운 데이터가 추가되기만 한다.
  * 인덱스는 걸지 않는다.
* 로그 취합 서버
  * 로그를 잘 취합하여 시스템이 쉽게 소비할 수 있도록 변경하는 서버
  * 데이터 취합 방식은 서비스의 용례에 따라 달라진다.
    * 실시간 결과를 빨리 보여줘야 하면 데이터 취합 주기를 짧게 가져간다.
    * 보통은 일주일에 한 번 정도로 로그를 취합해도 충분하다.
  * 따라서 데이터 취합의 실시간성이 얼마나 중요한지 확인해야 한다.
* 취합된 데이터
  * 빈도 테이블에 해당 주가 시작한 날짜를 추가한다.
* 작업 서버
  * 주기적으로 비동기적 작업을 실행하는 서버 집합
  * 트라이 자료구조 생성 및 트라이 데이터베이스에 저장
* 트라이 캐시
  * 분산 캐시 시스템으로 트라이 데이터를 메모리에 유지하여 읽기 연산 성능을 높인다.
  * 매주 트라이 데이터베이스의 스냅샷을 떠서 갱신
* 트라이 데이터베이스
  * 지속성 저장소
  * 문서 저장소(document store) : 새 트라이를 매주 만들 것이므로 주기적으로 트라이를 직렬화하여 데이터베이스에 저장
  * 키-값 저장소 : 트라이를 해시 테이블 형태로 변환
    * 트라이에 보관된 모든 접두어를 해시 테이블 키로 변환
    * 각 트라이 노드에 보관된 모든 데이터를 해시 테이블 값으로 변환

### 질의 서비스

* 설계안
  * 검색 질의를 로드밸런서로 전송
  * 로드밸런서는 해당 질의를 API 서버로 전송
  * API 서버는 트라이 캐시에서 데이터를 가져와 해당 요청에 대한 자동완성 검색어 제안 응답을 구성
  * 데이터가 트라이 캐시에 없으면 데이터를 데이터베이스에서 가져와 캐시에 채움
* 최적화 방안
  * AJAX 요청
  * 브라우저 캐싱
    * 제안된 검색어들을 브라우저 캐시에 넣어둔다.
  * 데이터 샘플링
    * 모든 질의 결과를 로깅하지 않고 일부만 로깅한다.

### 트라이 연산

* 트라이 생성
  * 작업 서버가 담당
  * 데이터 분석 서비스의 로그나 데이터베이스로부터 취합된 데이터 사용
* 트라이 갱신
  * 매주 한 번 갱신하는 방법
  * 트라이의 각 노드를 개별적으로 갱신하는 방법
    * 트라이 노드를 갱신하려면 그 모든 상위 노드도 갱신해야 함에 주의한다.
* 검색어 삭제
  * 트라이 캐시 앞에 필터 계층을 두고 부적절한 질의어가 반환되지 않도록 한다.
  * 필터 규칙에 따라 검색 결과를 자유롭게 변경할 수 있다.

### 저장소 규모 확장

* 트라이의 크기가 한 서버에 넣기에 너무 큰 경우에도 대응할 수 있어야 한다.
* 영어만 지원하는 경우 간단하게 첫 글자를 기준으로 샤딩하는 방법을 생각할 수 있다.
  * 사용 가능한 서버가 최대 26대로 제한된다.
  * 데이터를 균등하게 배분하기 불가능하다.
* 과거 질의 데이터의 패턴을 분석해 샤딩한다.
  * 검색어 대응 샤드 관리자가 어떤 검색어가 어느 저장소 서버에 저장되는지에 대한 정보를 관리
  * 이를 통해 검색어의 양을 비교해 샤드 분배

## 마무리

* 추가 사항
  * 다국어 지원 : 트라이에 유니코드 데이터 저장
  * 국가별로 인기 검색어 순위가 다른 경우 : 국가별로 다른 트라이 사용, 트라이를 CDN에 저장해 응답속도를 높임
  * 실시간으로 변하는 검색어 추이 반영
    * 샤딩
    * 순위 모델 변경 -> 최근 검색어에 보다 높은 가중치 부여
    * 데이터가 스트림 형태로 올 수 있다는 점(한 번에 모든 데이터를 동시에 사용할 수 없을 가능성이 있다는 점)을 고려
