# 키-값 저장소 설계

* 키-값 저장소
  * 비 관계형 데이터베이스
  * 저장소에 저장되는 값은 고유 식별자를 키로 가져야 한다.
  * 키-값 쌍에서의 키는 유일해야 한다.
  * 해당 키에 매달린 값은 키를 통해서만 접근할 수 있다.
  * 키는 일반 텍스트일 수도 있고 해시 값일 수도 있다.
  * 값은 어떤 것이 오든 상관없다.
  * 아마존 다이나모, memcached, 레디스 등이 있다.

## 문제 이해 및 설계 범위 확정

* 설계 목표
  * 키-값 쌍의 크기는 10KB 이하
  * 큰 데이터 저장 가능
  * 높은 가용성을 제공해야 한다. 즉, 시스템에 장애가 있더라도 빨리 응답해야 한다.
  * 높은 규모 확장성을 제공해야 한다. 즉, 트래픽 양에 따라 자동으로 서버 증설/삭제가 이루어져야 한다.
  * 데이터 일관성 수준은 조정이 가능해야 한다.
  * 응답 지연시간이 짧아야 한다.

## 분산 키-값 저장소

* 분산 해시 테이블이라고도 부른다.

### CAP 정리

* 데이터 일관성(consistency), 가용성(availability), 파티션 감내(partition tolerance)라는 세 가지 요구사항을 동시에 만족하는 분산 시스템을 설계하는 것은 불가능하다.
  * 데이터 일관성 : 분산 시스템에 접속하는 클라이언트는 어떤 노드에 접속하더라도 항상 같은 데이터를 얻을 수 있어야 한다.
  * 가용성 : 분산 시스템에 접속하는 클라이언트는 일부 노드에 장애가 발생하더라도 항상 응답을 받을 수 있어야 한다.
  * 파티션 감내 : 네트워크에 파티션(두 노드 사이의 통신 장애)이 생기더라도 시스템은 동작해야 한다.
* 네트워크 장애는 피할 수 없는 일이기에, 분산 시스템은 반드시 파티션 문제를 감내할 수 있어야 한다.
* 따라서 CP 시스템이나 AP 시스템으로 키-값 저장소를 구현한다.
* 데이터를 여러 노드에 복제해서 보관한다.

### 이상적 상태

* 네트워크가 파티션되지 않는 경우
* 한 노드에 저장된 데이터는 자동적으로 다른 노드에 복제된다.
* 데이터 일관성과 가용성도 만족한다.

### 실세계의 분산 시스템

* 파티션 문제를 피할 수 없다.
* 한 노드에 장애가 발생하는 경우, 가용성과 일관성 중 하나를 선택해야 한다.
  * CP 시스템 : 일관성을 선택한다면 서버 사이에 생길 수 있는 데이터 불일치 문제를 피하기 위해 각 서버에 대해 쓰기 연산을 중단시켜야 한다. 이렇게 하면 가용성이 깨진다.
    * 온라인 뱅킹 시스템에서는 데이터 일관성이 매우 중요하기에, CP 시스템을 선택한다.
  * AP 시스템 : 가용성을 선택한다면 오래된 데이터를 반환할 위험이 있지만 계속 읽기 및 쓰기 연산을 허용한다.
    * 파티션 문제가 해결되면 새 데이터를 장애가 발생했던 노드에 전달한다.

### 시스템 컴포넌트

* 데이터 파티션
  * 데이터를 작은 파티션들로 분할한 다음 여러 대의 서버에 저장하는 것을 말한다.
  * 중요 문제
    * 데이터를 여러 서버에 균등하게 배분
    * 노드 추가 및 삭제 시 데이터 이동 최소화
  * 이를 위해 안정 해시를 도입한다.
    * 해시 링에 서버를 배치하고 데이터인 키-값 쌍이 주어지면 키를 같은 링 위에 배치함으로써 어느 서버에 저장할지 결정한다.
  * 장점
    * 규모 확장 자동화(automatic scaling)
    * 다양성(heterogeneity) : 각 서버의 용량에 맞게 가상 노드 수 조정 가능
* 데이터 다중화(replication)
  * 높은 가용성과 안정성을 위해서 필요하다.
  * N개 서버에 데이터를 비동기적으로 다중화한다.
  * 키를 해시 링 위에 배치한 후, 그 지점으로부터 시계 방향으로 링을 순회하면서 만나는 서로 다른 N개 서버에 데이터 사본을 보관한다.
  * 같은 데이터 센터에 속한 노드는 자연 재해 등의 문제가 동시에 발생할 수 있기에, 데이터의 사본은 다른 센터의 서버에 보관하고, 센터들은 고속 네트워크로 연결한다.
* 데이터 일관성
  * 여러 노드에 다중화된 데이터는 적절히 동기화가 되어야 한다.
  * 정족수 합의(Quorum Consensus) 프로토콜을 사용하면 읽기 및 쓰기 연산에 일관성을 보장할 수 있다.
  * N : 사본 개수
  * W : 쓰기 연산에 대한 정족수
  * R : 읽기 연산에 대한 정족수
  * 연산이 성공한 것으로 간주되려면 적어도 W(R)개의 서버로부터 응답을 받아야 한다.
  * 클라이언트와 노드 사이에서 프록시 역할을 하는 중재자가 추가된다.
  * 중재자는 읽기 및 쓰기 연산을 서버에 요청하고 이에 대한 응답을 받아 몇 대의 서버가 정상적으로 응답했는지를 확인한다.
  * W와 R이 커질수록 데이터 일관성이 높아지지만 응답 속도는 느려진다.
  * 일관성 모델
    * 강한 일관성(strong consistency) : 모든 읽기 연산은 가장 최근에 갱신된 결과를 반환한다.
    * 약한 일관성(weak consistency) : 읽기 연산은 가장 최근에 갱신된 결과를 반환하지 못할 수도 있다.
    * 최종 일관성(eventual consistency) : 약한 일관성의 한 형태로, 갱신 결과가 결국에는 모든 사본에 반영된다.
    * 강한 일관성을 달성하기 위해서는 모든 사본에 현재 쓰기 연산의 결과가 반영될 때까지 해당 데이터에 대한 읽기 및 쓰기 연산을 금지해야 하는데, 이는 고가용성 시스템에 적잘하지 않다.
    * 보통 저장소는 최종 일관성 모델을 택하고 있다. 다만, 이 경우 쓰기 연산이 병렬적으로 발생하면 시스템에 저장된 값의 일관성이 깨질 수 있다. 이는 클라이언트가 해결해야 한다.
  * 비 일관성 해소 기법 : 데이터 버저닝
    * 버저닝 : 데이터를 변경할 때마다 해당 데이터의 새로운 버전을 만드는 것
    * 각 버전의 데이터는 변경 불가능하다.
    * 쓰기 연산이 병렬적으로 일어나는 경우를 해결하기 위해 벡터 시계를 사용한다.
    * 벡터 시계는 [서버, 버전]의 순서쌍을 데이터에 매단 것이다.
    * 벡터 시계는 D([S1, v1], [S2, v2], ... , [Sn, vn])과 같이 표현한다.
    * 데이터 D를 서버 Si에 기록하면 [Si, 1]을 추가하거나, [Si, vi]가 있다면 vi를 증가시킨다.
    * 벡터 시계를 사용하면 두 버전 중 어떤 것이 이전 버전인지, 아니면 충돌이 있는지를 쉽게 확인할 수 있다.
    * 단점
      * 충돌 감지 및 해소 로직이 클라이언트에 들어가야 하므로 클라이언트 구현이 복잡해진다.
      * [서버, 버전]의 순서쌍 개수가 매우 빠르게 늘어난다. 따라서 임계치 이상으로 길이가 길어지면 오래된 순서대로 벡터 시계에서 제거한다.
* 장애 처리
  * 장애 감지
    * 보통 두 대 이상의 서버가 동일하게 같은 서버의 장애를 보고해야 해당 서버에 실제로 장애가 발생했다고 간주한다.
    * 모든 노드 사이에 멀티캐스팅 채널을 구축해도 되지만, 이는 서버가 많을 때 비효율적이다.
    * 가십 프로토콜
      * 각 노드는 멤버십 목록을 유지한다. 멤버십 목록은 각 멤버 ID와 그 박동 카운터(heartbeat counter) 쌍의 목록이다.
      * 각 노드는 주기적으로 자신의 박동 카운터를 증가시킨다.
      * 각 노드는 무작위로 선정된 노드들에게 주기적으로 자기 박동 카운터 목록을 보낸다.
      * 박동 카운터 목록을 받은 노드는 멤버십 목록을 최신 값으로 갱신한다.
      * 어떤 멤버의 박동 카운터 값이 지정된 시간 동안 갱신되지 않으면 해당 멤버는 장애 상태인 것으로 간주한다.
  * 일시적 장애 처리
    * 엄격한 정족수 접근법을 쓴다면, 읽기와 쓰기 연산을 금지한다.
    * 느슨한 정족수(sloppy quorum) 접근법은 이 조건을 완화해 가용성을 높인다.
      * 정족수 요구사항을 강제하는 대신, 쓰기 연산을 수행할 W개의 서버와 읽기 연산을 수행할 R개의 서버를 해시 링에서 고른다. 장애 상태의 서버는 무시한다.
    * 장애 상태의 서버로 가는 요청은 다른 서버가 잠시 맡아 처리하고, 이후 변경사항은 해당 서버가 복구되었을 때 일괄 반영한다.
    * 이를 위해 임시로 쓰기 연산을 처리한 서버에는 그에 대한 단서(hint)를 남겨두는데, 이러한 장애 처리 방안을 단서 후 임시 위탁(hinted handoff)이라 한다.
  * 영구 장애 처리
    * 반-엔트로피(anti-entropy) 프로토콜을 구현해 사본들을 동기화한다.
    * 사본 간의 일관성이 망가진 상태를 탐지하고 전송 데이터 양을 줄이기 위해 머클(Merkle) 트리를 사용한다.
      * 머클 트리 : 각 노드에 자식 노드들에 보관된 값의 해시, 또는 자식 노드들의 레이블로부터 계산된 해시 값을 레이블로 붙여두는 트리
    * 머클 트리 생성 방법
      * 키 공간을 버킷으로 나눈다.
      * 버킷에 포함된 각각의 키에 균등 분포 해시 함수를 적용해 해시 값을 계산한다.
      * 버킷 별로 해시값을 계산한 후 해당 해시 값을 레이블로 갖는 노드를 만든다.
      * 자식 노드의 레이블로부터 새로운 해시 값을 계산하여 이진 트리를 상향식으로 구성해 나간다.
    * 루트 노드의 해시 값이 일치한다면 두 서버는 같은 데이터를 갖는 것이고, 만약 다르다면 왼쪽과 오른쪽 자식 노드의 해시 값을 재귀적으로 비교해 나가면서 다른 데이터를 갖는 버킷을 찾는다.
* 데이터 센터 장애 처리
  * 데이터 센터 장애는 정전, 네트워크 장애, 자연 재해 등 다양한 이유로 발생할 수 있다.
  * 따라서 여러 데이터 센터에 데이터를 다중화하는 것이 중요하다.

### 시스템 아키텍처 다이어그램

* 주된 기능
  * 클라이언트는 키-값 저장소가 제공하는 두 가지 API(get(key), put(key, value))와 통신한다.
  * 중재자는 클라이언트에게 키-값 저장소에 대한 프록시 역할을 하는 노드다.
  * 노드는 안정 해시의 해시 링 위에 분포한다.
  * 노드를 자동으로 추가 및 삭제할 수 있도록 시스템은 완전히 분산된다.
  * 데이터를 여러 노드에 다중화된다.
  * 모든 노드가 같은 책임을 지므로 SPOF는 존재하지 않는다.
* 쓰기 경로
  * 쓰기 요청이 커밋 로그 파일에 기록된다.
  * 데이터가 메모리 캐시에 기록된다.
  * 메오리 캐시가 가득 차거나 임계치에 도달하면 데이터는 디스크에 있는 SSTable에 기록된다.
    * SSTable : Sorted-String Table로, 키-값의 순서쌍을 정렬된 리스트 형태로 관리하는 테이블
* 읽기 경로
  * 데이터가 메모리에 있는지 검사한다.
  * 데이터가 메모리에 없으면 블룸 필터를 검사한다.
  * 블룸 필터를 통해 어떤 SSTable에 키가 보관되어 있는지 알아낸다.
  * SSTable에서 데이터를 가져온다.
  * 해당 데이터를 클라이언트에게 반환한다.

## 요약

* 분산 키-값 저장소의 기능과 기능 구현을 위한 기술
  * 대규모 데이터 저장 : 안정 해시를 사용한 부하 분산
  * 읽기 연산에 대한 높은 가용성 보장 : 데이터를 여러 데이터 센터에 다중화
  * 쓰기 연산에 대한 높은 가용성 보장 : 버저닝 및 벡터 시계를 사용한 충돌 해소
  * 데이터 파티션 : 안정 해시
  * 점진적 규모 확장성 : 안정 해시
  * 다양성(heterogeneity) : 안정 해시
  * 조절 가능한 데이터 일관성 : 정족수 합의
  * 일시적 장애 처리 : 느슨한 정족수 프로토콜과 단서 후 임시 위탁
  * 영구적 장애 처리 : 머클 트리
  * 데이터 센터 장애 대응 : 여러 데이터 센터에 걸친 데이터 다중화
