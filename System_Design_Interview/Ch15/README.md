# 구글 드라이브 설계

* 구글 드라이브
  * 파일 저장 및 동기화 서비스
  * 문서, 사진, 비디오, 기타 파일을 클라우드에 보관할 수 있도록 한다.
  * 어떤 단말에서도 이용 가능해야 하고, 모든 사람들이 쉽게 공유할 수 있어야 한다.

## 문제 이해 및 설계 범위 확정

* 설계 범위
  * 파일 추가
  * 파일 다운로드
  * 여러 단말에 파일 동기화
  * 파일 갱신 이력 조회
  * 파일 공유
  * 파일 편집 및 삭제, 새롭게 공유되었을 때 알람 표시
* 비기능적 요구사항
  * 안정성 : 데이터 손실이 없어야 한다.
  * 빠른 동기화 속도
  * 네트워크 대역폭 소비 최소화
  * 규모 확장성 : 많은 양의 트래픽 처리 가능
  * 높은 가용성 : 일부 서버에 장애가 발생하거나, 느려지거나, 네트워크 일부가 끊겨도 계속 사용 가능
* 개략적 추정치
  * 가입 사용자 : 오천만 명
  * DAU 사용자 : 천만 명
  * 모든 사용자에게 10GB의 무료 저장공간 할당
  * 매일 각 사용자가 평균 2개의 파일을 업로드한다고 가정, 각 파이르이 평균 크기는 500KB
  * 읽기:쓰기 비율은 1:1
  * 필요한 저장공간 총량 : 5천만 * 10GB = 500PB
  * 업로드 API QPS = 1천만 * 2회 업로드/24시간/3600초 = 약 240
  * 최대 QPS = QPS * 2 = 480

## 개략적 설계안 제시 및 동의 구하기

* 서버 한 대로 시작하는 경우
  * 구성
    * 파일을 올리고 다운로드하는 과정을 처리할 웹 서버
    * 사용자 데이터, 로그인 정보, 파일 정보 등의 메타데이터를 보관할 데이터베이스
    * 파일을 저장할 저장소 시스템(파일 저장을 위해 1TB의 공간 사용)
  * 과정
    * 아파치 웹 서버 설치
    * MySQL 데이터베이스 설치
    * 업로드되는 파일을 저장할 drive/ 디렉터리 준비
    * drive/ 디렉터리 안에 네임스페이스라 불리는 하위 디렉터리 두기
      * 각 네임스페이스 안에는 특정 사용자가 올린 파일 보관
      * 원래 파일과 같은 이름을 가짐

### API

* 파일 업로드 API
  * 단순 업로드 : 파일 크기가 작을 때
  * 이어 올리기(resumable upload) : 파일 사이즈가 크고 네트워크 문제로 업로드가 중단될 가능성이 높은 경우 사용
  * 인자
    * uploadType=resumable
    * data: 업로드할 로컬 파일
  * 이어 올리기 절차
    * 이어 올리기 URL을 받기 위한 최초 요청 전송
    * 데이터를 업로드하고 업로드 상태 모니터링
    * 업로드에 장애 발생 시 장애 발생시점부터 업로드 재시작
* 파일 다운로드 API
  * 인자
    * path : 다운로드할 파일의 경로
* 파일 갱신 히스토리 API
  * 인자
    * path : 갱신 히스토리를 가져올 파일의 경로
    * limit : 히스토리 길이의 최대치
* 모든 API는 사용자 인증을 필요로 하고 HTTPS 프로토콜을 사용해야 한다.
  * 클라이언트와 백엔드 서버가 주고받는 데이터를 보호하기 위한 것이다.

### 한 대 서버의 제약 극복

* 데이터 샤딩
* 저장소로 아마존 S3 사용
  * 업계 최고 수준의 규모 확장성, 가용성, 보안, 성능을 제공하는 객체 저장소 서비스
  * 같은 지역 안에서, 혹은 여러 지역에 걸쳐 다중화를 지원
* 로드밸런서
  * 네트워크 트래픽 분산
  * 특정 웹 서버에 장애 발생 시 자동으로 우회
  * 웹 서버 : 로드밸런서 추가 시 더 많은 웹 서버를 손쉽게 추가 가능
* 메타데이터 데이터베이스
  * 데이터베이스를 파일 저장 서버에서 분라해 SPOF를 회피
  * 다중화 및 샤딩 정책 적용 -> 규모 확장성
*  파일 저장소
  * S3를 파일 저장소로 사용
  * 다중화를 통해 가용성과 데이터 무손실 보장

### 동기화 충돌

* 두 명 이상의 사용자가 같은 파일이나 폴더를 동시에 업데이트하는 경우
* 먼저 처리되는 변경은 성공으로, 나중에 처리되는 변경은 충돌이 발생한 것으로 표시
* 오류가 발생하는 경우 충돌이 발생한 사용자가 가지고 있는 로컬 사본과 서버에 있는 최신 버전이 혼재
  * 사용자는 두 파일을 하나로 합칠지, 아니면 둘 중 하나를 다른 파일로 대체할지를 결정해야 한다.

### 개략적 설계안

* 사용자 단말
* 블록 저장소 서버
  * 파일 블록을 클라우드 저장소에 업로드하는 서버
  * 파일을 여러 개의 블록으로 나누어 클라우드에 저장
  * 각 블록에는 고유한 해시값 할당, 해시값은 메타데이터 데이터베이스에 저장
  * 각 블록은 독립적인 객체로 취급하며 클라우드 저장소 시스템에 보관
  * 파일 재구성 시 블록들을 원래 순서대로 합쳐야 함
* 클라우드 저장소
  * 파일을 블록 단위로 나눠 클라우드 저장소에 보관
* 아카이빙 저장소(cold storage)
  * 오랫동안 사용되지 않은 비활성 데이터를 저장하기 위한 컴퓨터 시스템
* 로드밸런서
* API 서버
  * 파일 업로드 외 사용자 인증, 사용자 프로파일 관리, 파일 메타데이터 갱신을 담당
* 메타데이터 데이터베이스
  * 사용자, 파일, 블록, 버전 등의 메타데이터 정보를 관리
  * 실제 파일은 여기가 아닌 클라우드에 보관
* 메타데이터 캐시
  * 자주 쓰는 메타데이터를 캐시
* 알림 서비스
  * 클라이언트에게 파일 추가, 편집, 삭제를 알려 파일의 최신 상태를 확인하도록 하는 데 사용
* 오프라인 사용자 백업 큐
  * 클라이언트가 접속 중이 아닌 경우 파일 최신 정보를 넣는 큐
  * 나중에 클라이언트가 접속했을 때 동기화될 수 있도록 함

## 상세 설계

### 블록 저장소 서버

* 큰 파일들은 업데이트 발생 시 전체 파일을 서버로 보내면 네트워크 대역폭을 많이 소비한다.
* 위 문제를 최적화하는 방법
  * 델타 동기화 : 파일 수정 시 전체 파일 대신 수정이 일어난 블록만 동기화
  * 압축 : 블록 단위로 압축
    * 압축 알고리즘은 파일 유형에 따라 결정
* 파일 업로드 시 해야 할 일
  * 블록 단위로 나누기
  * 각 블록에 압축 알고리즘을 적용하기
  * 암호화
  * 전체 파일을 저장소 시스템으로 보내는 대신 수정된 블록만 전송

### 높은 일관성 요구사항

* 강한 일관성 모델을 기본으로 지원해야 한다.
  * 같은 파일이 단말이나 사용자에 따라 다르게 보이면 안 된다.
  * 메타데이터 캐시와 데이터베이스에도 같은 원칙이 적용된다.
* 메모리 캐시는 보통 최종 일관성 모델을 지원한다.
  * 캐시에 보관된 사본과 데이터베이스에 있는 원본이 일치한다.
  * 데이터베이스에 보관된 원본에 변경이 발생하면 캐시에 있는 사본을 무효화한다.
* 관계형 데이터베이스는 ACID를 보장하므로 강한 일관성을 보장하기 쉽지만, NoSQL 데이터베이스는 이를 기본으로 지원하지 않는다. 따라서 동기화 로직을 프로그램해 넣어야 한다.

### 메타데이터 데이터베이스

* user : 이름, 이메일, 프로파일 사진 등 사용자에 관계된 기본적 정보들 보관
* device : 단말 정보 보관
  * push_id : 모바일 푸시 알림을 보내고 받기 위한 것
* namespace : 사용자의 루트 디렉터리 정보 보관
* file : 파일의 최신 정보
* file_version : 파일의 갱신 이력 보관. 읽기 전용으로 갱신 이력이 훼손되는 것을 방지
* block : 파일 블록에 대한 정보를 보관. 특정 버전의 파일은 파일 블록을 올바른 순서로 조합하면 복원 가능

### 업로드 절차

* 두 가지 요청이 병렬적으로 전송
  * 파일 메타데이터 추가
    * 클라이언트가 새 파일의 메타데이터를 추가하기 위한 요청 전송
    * 새 파일의 메타데이터를 데이터베이스에 저장하고 업로드 상태를 대기 중으로 변경
    * 새 파일이 추가되었음을 알림 서비스에 통지
    * 알림 서비스는 관련된 클라이언트에게 파일이 업록드되고 있음을 알림
  * 파일을 클라우드 저장소에 업로드
    * 클라이언트가 파일을 블록 저장소 서버에 업로드
    * 블록 저장소 서버는 파일을 블록 단위로 쪼갠 다음 압축, 암호화 후 클라우드 저장소에 전송
    * 업로드 완료 후 클라우드 스토리지는 완료 콜백 호출. 콜백 호출은 API 서버로 전송
    * 메타데이터 DB에 기록된 해당 파일의 상태를 완료로 변경
    * 알림 서비스에 파일 업로드가 끝났음을 통지
    * 알림 서비스는 관련된 클라이언트에게 파일 업로드가 끝났음을 알림

### 다운로드 절차

* 파일 다운로드는 파일 추가 및 편집 시 자동으로 시작
* 파일 편집 및 추가 사실 감지 방법
  * 클라이언트가 접속 중인 경우 알림 서비스가 변경 발생을 알림
  * 네트워크에 연결된 상태가 아닌 경우 데이터를 캐시에 보관하고 클라이언트가 접속 중으로 바뀌면 해당 클라이언트가 새 버전을 가져가도록 함
* 다운로드 절차
  * 알림 서비스가 누군가 파일을 변경했음을 클라이언트에게 알림
  * 알림 확인한 클라이언트는 새로운 메타데이터 요청
  * API 서버는 메타데이터 데이터베이스에게 새 메타데이터를 얻어옴
  * 클라이언트에게 메타데이터 반환
  * 클라이언트는 새 메타데이터를 받는 즉시 블록 다운로드 요청 전송
  * 블록 저장소 서버는 클라우드 저장소에서 블록 다운로드
  * 클라우드 저장소는 블록 서버에 요청된 블록 반환
  * 블록 저장소 서버는 클라이언트에게 요청된 블록 반환. 클라이언트는 전송된 블록을 사용해 파일 재구성

### 알림 서비스

* 방식
  * 롱 폴링 : 드롭박스가 채택한 방식
  * 웹소켓 : 클라이언트와 서버 사이에 지속적인 통신 채널 제공. 따라서 양방향 통신 가능
* 롱 폴링을 사용하는 이유
  * 양방향 통신이 필요하지 않다. 서버는 클라이언트에게 파일이 변경된 사실을 알려야 하지만, 그 반대 방향의 통신은 요구되지 않는다.
  * 웹소켓은 실시간 양방향 통신이 요구되는 채팅에 적합하다. 구글 드라이브의 경우 알림을 보낼 일이 자주 발생하지 않고, 알림을 보내야 하는 경우에도 단시간에 많은 양의 데이터를 보낼 일이 없다.
* 롱 폴링을 쓰게 되면 각 클라이언트는 알림 서버와 롱 폴링용 연결을 유지하다가 특정 파일에 대한 변경을 감지하면 해당 연결을 끊는다.
  * 이때 클라이언트는 반드시 메타데이터 서버와 연결해 파일의 최신 내역을 다운로드해야 한다.
  * 다운로드 작업 완료 혹은 연결 타임아웃 시간에 도달한 경우 즉시 새 요청을 보내 롱 폴링 연결을 복원하고 유지해야 한다.

### 저장소 공간 절약

* 파일 갱신 이력 보존 및 안전성 보장을 위해 파일의 여러 버전을 여러 데이터센터에 보관해야 한다.
* 모든 버전을 자주 백업하면 저장용량을 너무 빨리 소진할 가능성이 있다.
* 위 문제를 피하고 비용응 절감하는 방법
  * 중복 제거 : 중복된 파일 블록을 계정 차원에서 제거하는 방법. 중복된 블록인지는 해시 값으로 비교
  * 자능적 백업 전략 도입
    * 한도 설정 : 보관해야 하는 파일 버전 개수에 상한을 둔다.
    * 중요한 버전만 보관 : 불필요한 버전과 사본은 버리고 중요한 것만 골라낸다.
  * 자주 쓰이지 않는 데이터는 아카이빙 저장소로 옮긴다.

### 장애 처리

* 로드밸런서 장애 : 부 로드밸런서가 활성화되어 트래픽을 이어받아야 한다.
  * 로드밸런서끼리는 보통 박동 신호를 주기적으로 보내서 상태를 모니터링한다.
* 블록 저장소 서버 장애 : 다른 서버가 미완료 상태 또는 대기 상태인 작업을 이어받아야 한다.
* 클라우드 저장소 장애 : S3 버킷은 여러 지역에 다중화할 수 있으므로 한 지역에서 장애 발생 시 다른 지역에서 파일을 가져온다.
* API 서버 장애 : 무상태 서버이므로 트래픽을 다른 서버로 보내기만 하면 된다.
* 메타데이터 캐시 장애 : 캐시 서버도 다중화해 다른 노드에서 데이터를 가져온다.
* 메타데이터 데이터베이스 장애
  * 주 데이터베이스 서버 장애 : 부 데이터베이스 서버 가운데 하나를 주 데이터베이스 서버로 교체
  * 부 데이터베이스 서버 장애 : 다른 부 데이터베이스 서버가 읽기 연산 처리
* 알림 서비스 장애
  * 알림 서비스는 많은 사용자와의 롱 폴링 연결을 유지한다.
  * 장애 발생 시 많은 사용자가 롱 폴링 연결을 다시 해야 한다.
  * 동시에 롱 폴링을 복구하는 것은 불가능해 복구할 때 속도가 느릴 수 있다.
* 오프라인 사용자 백업 큐 장애 : 다중화

## 마무리

* 블록 저장소 서버를 거치지 않고 파일을 클라우드 저장소 직접 업로드하는 경우
  * 분할, 압축, 암호화 로직을 클라이언트에 두어야 하므로 플랫폼별로 따로 구현해야 한다.
  * 클라이언트가 해킹당할 위험이 있어 암호화 로직을 클라이언트 안에 두는 것은 적절치 않다.
* 접속상태를 관리하는 로직을 별도 서비스로 옮긴다.
  * 관련 로직을 알림 서비스에서 분리해 내면, 다른 서비스에서도 쉽게 활용할 수 있다.
